{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goldsmiths University of London\n",
    "### Authors...: Sandor Kanda (skand001) + Carlos Alves (cdeol003)\n",
    "### Created...: 14/02/2023\n",
    "\n",
    "## Data Mining Coursework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: \n",
    "### This task is based on the Sonar real data seen previously in class. Several objects which can be rock or metal cylinders are scanned on different angles and under different conditions, with sonar signals. 60 measurements are recorded per columns for each object (one record per object) and these are the predictors called A1, A2, …, A60. The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is metal cylinder, and this is the outcome variable called Class. Two datasets are provided to you: a training dataset in the sonar_train.csv file, and a test dataset in the sonar_test.csv file. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframes credit default test and train\n",
    "df_credit_test = pd.read_csv('creditdefault_test.csv')\n",
    "df_credit_train = pd.read_csv('creditdefault_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframes sonar test and train\n",
    "df_sonar_test = pd.read_csv('sonar_test.csv')\n",
    "df_sonar_train = pd.read_csv('sonar_train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframes sonar test and train\n",
    "df_sonar_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe sonar test\n",
    "df_sonar_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a statistical summary of the dataframes sonar test and train\n",
    "df_sonar_test.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataframe sonar test\n",
    "df_credit_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataframe sonar train\n",
    "df_credit_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the target variable in the dataframe sonar train\n",
    "df_sonar_train['Class'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of the target variable in the dataframe sonar train')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the target variable in the dataframe sonar test\n",
    "df_sonar_test['Class'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of the target variable in the dataframe sonar test')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix X_train and the target vector y_train for the dataframe sonar train \n",
    "X_train = df_sonar_train.drop('Class', axis=1)\n",
    "y_train = df_sonar_train['Class']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the K-NN model on the Training set using the euclidean distance metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Library from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier class\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the classifier object using the euclidean distance metric using 1 nearest neighbour\n",
    "classifier = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "# Fit the classifier to the data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable for the dataframe sonar test\n",
    "y_pred = classifier.predict(df_sonar_test.drop('Class', axis=1))\n",
    "\n",
    "# Import the confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(df_sonar_test['Class'], y_pred)\n",
    "\n",
    "# Create the classification report\n",
    "cr = classification_report(df_sonar_test['Class'], y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n",
    "\n",
    "# Print accuracy score with 2 decimal places\n",
    "print('\\n>> Accuracy score: {:.2f}%'.format((cm[0,0] + cm[1,1])/len(y_pred) * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics to measure the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix with TP, TN, FP, and FN values\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate TP, TN, FP, and FN from the confusion matrix\n",
    "TP = cm[1,1]\n",
    "TN = cm[0,0]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "# Create the confusion matrix plot\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Add the TP, TN, FP, and FN values to the plot\n",
    "plt.text(0.5, -0.2, \"True Positives: {}\".format(TP), size=12, ha=\"center\", \n",
    "         transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.3, \"True Negatives: {}\".format(TN), size=12, ha=\"center\", \n",
    "         transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.4, \"False Positives: {}\".format(FP), size=12, ha=\"center\", \n",
    "         transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.5, \"False Negatives: {}\".format(FN), size=12, ha=\"center\", \n",
    "         transform=plt.gca().transAxes)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a K-Nearest Neighbors classifier without using the scikit-learn library\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implements the KNN algorithm using Euclidean distance metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Create the feature matrix X_train and the target vector y_train for the dataframe sonar train\n",
    "class KNearestNeighbors:\n",
    "\n",
    "    # Initialize the class with the number of nearest neighbors\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate the euclidean distance between the test point and all training points\n",
    "        distances = np.sqrt(np.sum((X - self.X_train)**2, axis=1))\n",
    "\n",
    "        # Sort the distances and return the indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Extract the labels of the k nearest neighbors\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # Return the most common class label\n",
    "        from collections import Counter\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the KNearestNeighbors class and fit it to your data\n",
    "classifier = KNearestNeighbors(k=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict method to make predictions on new data\n",
    "y_pred = classifier.predict(df_sonar_test.drop('Class', axis=1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the y_pred has the same results as using the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier class\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the classifier object using the euclidean distance metric with 1 nearest neighbour\n",
    "classifier = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "# Fit the classifier to the data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Import the confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(df_sonar_test['Class'], y_pred)\n",
    "\n",
    "# Create the classification report\n",
    "cr = classification_report(df_sonar_test['Class'], y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n",
    "\n",
    "# Print accuracy score with 2 decimal places\n",
    "print('\\n>> Accuracy score: {:.2f}%'.format((cm[0,0] + cm[1,1])/len(y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy, Precision, Recall, and F1 score\n",
    "accuracy = (cm[0,0] + cm[1,1])/len(y_pred)\n",
    "precision = cm[1,1]/(cm[1,1] + cm[0,1])\n",
    "recall = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# Print the accuracy, precision, recall, and F1 score\n",
    "print('\\n>> Accuracy...: {:.2f}%'.format(accuracy * 100))\n",
    "print('>> Precision..: {:.2f}%'.format(precision * 100))\n",
    "print('>> Recall.....: {:.2f}%'.format(recall * 100))\n",
    "print('>> F1 score...: {:.2f}%'.format(f1_score * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy, precision, recall, and F1 score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the plot\n",
    "plt.bar(['Accuracy', 'Precision', 'Recall', 'F1 score'], [accuracy, precision, recall, f1_score])\n",
    "plt.title('Accuracy, Precision, Recall, and F1 score')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45d680b53dd59098257682a39d3543fddeca95e541b2c6ea1b49c6cd756418f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
