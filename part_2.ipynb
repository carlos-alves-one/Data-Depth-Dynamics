{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goldsmiths University of London\n",
    "\n",
    "### Team Lead..........: Carlos Alves (cdeol003)\n",
    "### Team Member..: Sandor Kanda (skand001)\n",
    "### Created...: 14/02/2023\n",
    "\n",
    "## Data Mining Coursework - Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries and load the datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import seaborn for visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Import sklearn model selection for splitting data into training and testing sets, grid search for hyperparameter tuning and cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "# Import sklearn metrics for k-nearest neighbors classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import sklearn metrics for decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import sklearn metrics for random forest classifier, bagging classifier and adaboost classifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "# Import sklearn metrics for support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import sklearn metrics for accuracy score, confusion matrix and classification report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import RandomizedSearchCV for hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"creditdefault_train.csv\")\n",
    "test_df = pd.read_csv(\"creditdefault_test.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the training and testing datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into features and target variables\n",
    "X_train = train_df.drop(\"Y\", axis=1)\n",
    "y_train = train_df[\"Y\"]\n",
    "\n",
    "# Split the testing dataset into features and target variables\n",
    "X_test = test_df.drop(\"Y\", axis=1)\n",
    "y_test = test_df[\"Y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the best models and their scores\n",
    "best_models = {}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. k-Nearest Neighbours :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the instance of the k-nearest neighbors classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "knn_params = {'n_neighbors': list(range(1, 50))}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_knn = knn_grid.best_estimator_\n",
    "knn_score = knn_grid.best_score_\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models['kNN'] = (best_knn, knn_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Trees :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the instance of the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "dt_params = {'max_depth': list(range(1, 20))}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "dt_grid = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_score = dt_grid.best_score_\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models['Decision Tree'] = (best_dt, dt_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the instance of the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "rf_params = {'n_estimators': [10, 50, 100, 150, 200]}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_score = rf_grid.best_score_\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models['Random Forest'] = (best_rf, rf_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the instance of bagging classifier\n",
    "bag = BaggingClassifier(random_state=42)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "bag_params = {'n_estimators': [10, 50, 100, 150, 200]}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "bag_grid = GridSearchCV(bag, bag_params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "bag_grid.fit(X_train, y_train)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_bag = bag_grid.best_estimator_\n",
    "bag_score = bag_grid.best_score_\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models['Bagging'] = (best_bag, bag_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AdaBoost :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the instance of adaboost classifier\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "ada_params = {'n_estimators': [10, 50, 100, 150, 200]}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "ada_grid = GridSearchCV(ada, ada_params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "ada_grid.fit(X_train, y_train)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_ada = ada_grid.best_estimator_\n",
    "ada_score = ada_grid.best_score_\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models['AdaBoost'] = (best_ada, ada_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the instance of support vector machine classifier\n",
    "# svm = SVC(random_state=42)\n",
    "\n",
    "# # Create a dictionary of hyperparameters to tune\n",
    "# svm_params = {'C': np.logspace(-1, 2, 4), 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# # Perform randomized search to find the best hyperparameters\n",
    "# n_iter_search = 5  # Change this number to control the number of iterations\n",
    "\n",
    "# # Create an instance of RandomizedSearchCV\n",
    "# svm_rand = RandomizedSearchCV(svm, svm_params, n_iter=n_iter_search, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# # Fit the randomized search object to the training data\n",
    "# svm_rand.fit(X_train, y_train)\n",
    "\n",
    "# # Store the best model and its score\n",
    "# best_svm = svm_rand.best_estimator_\n",
    "# svm_score = svm_rand.best_score_\n",
    "\n",
    "# # Add the best model and its score to the dictionary\n",
    "# best_models['SVM'] = (best_svm, svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from functools import partial\n",
    "\n",
    "# Objective function for SVM\n",
    "def svm_objective(trial, X, y):\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-1, 1e2)\n",
    "    # kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\"])\n",
    "    \n",
    "    svm = SVC(C=C, kernel=kernel, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(svm, X, y, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    return score.mean()\n",
    "\n",
    "# Optimize the objective function\n",
    "svm_study = optuna.create_study(direction=\"maximize\")\n",
    "svm_opt = partial(svm_objective, X=X_train, y=y_train)\n",
    "svm_study.optimize(svm_opt, n_trials=5)\n",
    "\n",
    "# Store the best model and its score\n",
    "best_svm = SVC(**svm_study.best_params, random_state=42)\n",
    "best_svm.fit(X_train, y_train)\n",
    "svm_score = svm_study.best_value\n",
    "\n",
    "# Add the best model and its score to the dictionary\n",
    "best_models[\"SVM\"] = (best_svm, svm_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model and its score\n",
    "best_model_name, (best_model, best_score) = max(best_models.items(), key=lambda x: x[1][1])\n",
    "\n",
    "# Print the best model and its score\n",
    "print(f\"\\nBest Model.............: {best_model_name} with accuracy {best_score:.2%}\")\n",
    "\n",
    "# Print the best model's parameters\n",
    "print(\"\\n>> Best Model Parameters\\n\")\n",
    "\n",
    "# Loop through the best model's parameters and print them in a new line\n",
    "for key, value in best_model.get_params().items():\n",
    "    print(key, \":\", value)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best model on the test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable for the test dataset\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Store the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "# Print the accuracy score, confusion matrix and classification report\n",
    "print(\"\\nAccuracy..........: {:.2f}%\".format(accuracy))\n",
    "print(\"\\nConfusion Matrix..:\\n\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n>> Classification Report\\n\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot hyperparameter vs accuracy for each algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty figure with a size of 15 x 10\n",
    "plt.figure(figsize=(15, 10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. kNN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(231)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot(list(range(1, 50)), knn_grid.cv_results_['mean_test_score'])\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.title('kNN')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decison Tree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(232)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot(list(range(1, 20)), dt_grid.cv_results_['mean_test_score'])\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.title('Decision Tree')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(233)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot([10, 50, 100, 150, 200], rf_grid.cv_results_['mean_test_score'])\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.title('Random Forest')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(234)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot([10, 50, 100, 150, 200], bag_grid.cv_results_['mean_test_score'])\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.title('Bagging')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AdaBoost :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(235)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot([10, 50, 100, 150, 200], ada_grid.cv_results_['mean_test_score'])\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with 2 rows and 3 columns\n",
    "plt.subplot(236)\n",
    "\n",
    "# Store the grid search object for the support vector machine classifier\n",
    "svm_grid = svm_rand\n",
    "\n",
    "# Extract the training and testing accuracies for linear and rbf kernels\n",
    "linear_scores = svm_grid.cv_results_['mean_test_score'][::2]\n",
    "rbf_scores = svm_grid.cv_results_['mean_test_score'][1::2]\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.plot([0.1, 1, 10, 100], linear_scores, label='Linear')\n",
    "plt.plot([0.1, 1, 10, 100], rbf_scores, label='RBF')\n",
    "\n",
    "# Set the title, x-axis label and y-axis label\n",
    "plt.title('SVM')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the layout of the subplots and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
